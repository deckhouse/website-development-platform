---
title: AI-агент
---

{{< alert level="warning" >}}
Экспериментальный функционал
{{< /alert >}}

## Описание

AI-агент — это интеллектуальный помощник, интегрированный в Deckhouse Development Platform, который позволяет получать ответы на вопросы о платформе, анализировать данные из каталога и выполнять различные задачи с помощью инструментов MCP (Model Context Protocol).

AI-агент использует настраиваемые AI-провайдеры для обработки запросов и может работать с различными языковыми моделями, включая OpenAI GPT, Ollama и кастомные REST API.

## Настройка AI-провайдеров

### Типы провайдеров

Платформа поддерживает три типа AI-провайдеров:

1. **OpenAI** — для работы с моделями OpenAI (GPT-4, GPT-3.5 и др.)
2. **Ollama** — для работы с локальными моделями через Ollama
3. **Custom** — для работы с любым кастомным REST API, поддерживающим совместимый формат

### Создание провайдера OpenAI (ChatGPT)

Для настройки провайдера OpenAI выполните следующие шаги:

1. Откройте профиль пользователя и перейдите на вкладку **AI-провайдеры**
2. Нажмите кнопку **Добавить**
3. Заполните форму:
   - **Название**: `ChatGPT` (или любое другое удобное имя)
   - **Провайдер**: выберите `OpenAI`
   - **Модель**: укажите название модели, например `gpt-4` или `gpt-3.5-turbo`
   - **URL**: `https://api.openai.com/v1/chat/completions`
   - **Метод**: `POST`
   - **Заголовки**: добавьте заголовок авторизации:

     ```sh
     Authorization: Bearer YOUR_OPENAI_API_KEY
     ```

     где `YOUR_OPENAI_API_KEY` — ваш API ключ от OpenAI

4. Нажмите **Сохранить**

> **Важно**: API ключ OpenAI можно получить на странице [API Keys](https://platform.openai.com/api-keys) в личном кабинете OpenAI.

### Создание провайдера Ollama

Для настройки локального провайдера Ollama:

1. Убедитесь, что Ollama запущена на вашем сервере
2. Создайте нового провайдера:
   - **Название**: `Ollama Local`
   - **Провайдер**: выберите `Ollama`
   - **Модель**: укажите название модели, например `llama2` или `mistral`
   - **URL**: `http://localhost:11434/api/generate` (или адрес вашего сервера Ollama)
   - **Метод**: `POST`

3. Нажмите **Сохранить**

### Создание кастомного провайдера

Для настройки кастомного REST API провайдера:

1. Создайте нового провайдера и выберите тип **Custom**
2. Заполните основные поля (URL, метод, заголовки авторизации)
3. Нажмите **Сохранить**

#### Поле ответа (Response Field)

Поле **Поле ответа** определяет путь к полю в JSON ответе API, которое содержит текст ответа модели. Это поле используется для извлечения ответа из структуры JSON, возвращаемой API провайдера.

**Формат указания пути:**
- Используйте точечную нотацию для доступа к вложенным полям
- Для массивов используйте индекс, начиная с 0
- Поле необязательно — если не указано, система попытается найти ответ в стандартных местах

**Примеры:**

Для OpenAI-совместимых API:

```json
choices.0.message.content
```

Это означает: взять первый элемент массива `choices`, затем поле `message`, затем поле `content`.

Для других форматов возможны значения `response.text`, `content`, `answer`.

**Как определить правильный путь:**
1. Выполните тестовый запрос к вашему API
2. Изучите структуру JSON ответа
3. Найдите поле, содержащее текст ответа модели
4. Укажите путь к этому полю в точечной нотации

#### Шаблон тела запроса (Request Body Template)

Поле **Шаблон тела запроса** определяет структуру JSON запроса, который будет отправляться к API провайдера. В шаблоне можно использовать переменные, которые будут автоматически заменены на актуальные значения.

**Доступные переменные:**
- `{{.prompt}}` — текст вопроса пользователя (будет автоматически экранирован для JSON)
- `{{.model}}` — название модели, указанное в настройках провайдера

**Примеры шаблонов:**

Для OpenAI-совместимых API:

```json
{
  "model": "{{.model}}",
  "messages": [
    {
      "role": "user",
      "content": "{{.prompt}}"
    }
  ],
  "temperature": 0.7
}
```

Для API с другим форматом:

```json
{
  "messages": [
    {
      "content": "{{.prompt}}",
      "role": "user"
    }
  ],
  "model": "{{.model}}",
  "stream": false
}
```

Для простых API:

```json
{
  "query": "{{.prompt}}",
  "model_name": "{{.model}}"
}
```

**Важные замечания:**
- Шаблон должен быть валидным JSON
- Переменные `{{.prompt}}` и `{{.model}}` будут автоматически заменены при отправке запроса
- Значение `{{.prompt}}` автоматически экранируется для безопасной вставки в JSON
- Вы можете добавить любые дополнительные поля, необходимые для вашего API (temperature, max_tokens, и т.д.)

**Пример полной настройки кастомного провайдера:**

1. **Название**: `My Custom API`
2. **Провайдер**: `Custom`
3. **Модель**: `my-model-v1`
4. **URL**: `https://api.example.com/v1/chat`
5. **Метод**: `POST`
6. **Заголовки**:

   ```sh
   Authorization: Bearer YOUR_API_KEY
   Content-Type: application/json
   ```

7. **Поле ответа**: `choices.0.message.content`
8. **Шаблон тела запроса**:

   ```json
   {
     "model": "{{.model}}",
     "messages": [
       {
         "role": "user",
         "content": "{{.prompt}}"
       }
     ],
     "temperature": 0.7,
     "max_tokens": 1000
   }
   ```

## Работа с AI-агентом

### Открытие чата

AI-агент доступен через боковую панель чата в правой части интерфейса. Для открытия чата:

1. Нажмите на кнопку чата в правом нижнем углу экрана
2. Или используйте горячую клавишу `/` для быстрого доступа

### Выбор провайдера

В верхней части чата находится селектор провайдеров. Выберите нужный провайдер из списка доступных. Если у вас настроен только один провайдер, он будет выбран автоматически.

### Доступные инструменты (MCP Tools)

AI-агент использует инструменты MCP (Model Context Protocol) для работы с платформой. Полный список доступных инструментов с их описанием, параметрами и примерами использования доступен в [документации MCP-сервера](./mcp_server.html).

Основные возможности инструментов:
- Получение и анализ данных из каталога платформы
- Консультации по документации платформы

### Просмотр доступных инструментов

В чате отображается список всех доступных инструментов с их описаниями и примерами использования. Вы можете:

- Раскрыть раздел **Доступные инструменты** для просмотра списка
- Раскрыть каждый инструмент для просмотра его параметров и примеров
- Кликнуть на пример, чтобы вставить его в поле ввода

### Задавание вопросов

Вы можете задавать вопросы AI-агенту в свободной форме:

- **Вопросы о платформе**: "Как создать новое действие?", "Как настроить автоматизацию?"
- **Анализ данных**: "Сколько сервисов в статусе разработки?", "Покажи все сервисы с ошибками"
- **Работа с каталогом**: "Найди все сервисы, где жизненный цикл равен production"

AI-агент автоматически определит, какой инструмент использовать, и выполнит запрос.

### Особенности работы

1. **Анализ данных**: AI-агент не просто возвращает сырые данные, а анализирует их и предоставляет структурированные ответы
2. **Фильтрация**: Вы можете запрашивать данные с условиями, и агент выполнит фильтрацию
3. **Агрегация**: Агент может подсчитывать количество, группировать данные и предоставлять статистику
4. **Контекст документации**: При вопросах о платформе агент использует официальную документацию

### Отладка

Если ответ агента кажется некорректным, вы можете просмотреть логи отладки, нажав на кнопку с иконкой вопроса рядом с ответом. Это поможет понять, какие инструменты были вызваны и какие данные были получены.

## Примеры использования

### Пример 1: Анализ сервисов

**Вопрос:**

```sh
Получи все сервисы, найди те, у которых параметр 'Жизненный цикл' равен 'разработка', и выведи их количество
```

**Результат:**
Агент использует инструменты MCP для получения данных о сервисах, проанализирует их и вернет количество сервисов в разработке.

### Пример 2: Комплексный анализ

**Вопрос:**

```sh
Покажи все сервисы с ошибками и их основные причины
```

**Результат:**
Агент получит данные о сервисах, проанализирует их статусы здоровья, найдет ошибки и предоставит структурированный список с причинами.

## Рекомендации

1. **Используйте конкретные вопросы**: Чем конкретнее вопрос, тем точнее будет ответ
2. **Указывайте параметры явно**: Если вы знаете название ресурса или параметр, укажите его в вопросе
3. **Экспериментируйте**: AI-агент понимает естественный язык, пробуйте разные формулировки вопросов
